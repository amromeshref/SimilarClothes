{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b446e73d",
   "metadata": {},
   "source": [
    "# Siamese Training: Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b189b9a",
   "metadata": {},
   "source": [
    "#### General Steps to Follow\n",
    "\n",
    "1. Importing Packages\n",
    "2. Defining x_train, x_test, y_train, y_test\n",
    "3. Building and training the siamese network\n",
    "4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3df787",
   "metadata": {},
   "source": [
    "## 1) Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee08f7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 15:52:32.313443: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 15:52:33.271061: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 15:52:33.275769: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 15:52:34.647396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Layer,Concatenate, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd681f05",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ed2b5",
   "metadata": {},
   "source": [
    "## 2) Defining x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bef2c1",
   "metadata": {},
   "source": [
    "#### Loading the training and test data from \"other data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1605e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"../other data/train_data.npy\", allow_pickle = True)\n",
    "test_data = np.load(\"../other data/test_data.npy\"  , allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5247da",
   "metadata": {},
   "source": [
    "* x_train and x_test will contain pairs of the anchor image and the validation image(positive or negative image).\n",
    "* y_train and y_test will contain the label of each pair:\n",
    "  - 1 if the pairs are similar images.\n",
    "  - 0 if the pairs are different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990fdc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[:,0:2]\n",
    "y_train = train_data[:,2]\n",
    "x_test = test_data[:,0:2]\n",
    "y_test = test_data[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d1518",
   "metadata": {},
   "source": [
    "#### Reshaping the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d985c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 15:52:51.753365: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "x1_train = x_train[:,0]                   #anchor images\n",
    "x1_train = np.array(x1_train.tolist())    \n",
    "x2_train = x_train[:,1]                   #validation images(positive/negative)\n",
    "x2_train = np.array(x2_train.tolist())\n",
    "\n",
    "x1_test = x_test[:,0]                    #anchor images\n",
    "x1_test = np.array(x1_test.tolist())\n",
    "x2_test = x_test[:,1]                    #validation images(positive/negative)\n",
    "x2_test = np.array(x2_test.tolist())\n",
    "\n",
    "y_train = tf.convert_to_tensor(y_train.tolist())\n",
    "y_test = tf.convert_to_tensor(y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f9ea44",
   "metadata": {},
   "source": [
    "#### Checking the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243fcf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "Shape of anchor images    :  (896, 105, 105, 3)\n",
      "Shape of validation images:  (896, 105, 105, 3)\n",
      "Shape of labels           :  (896,)\n",
      "--------------------------------------------------\n",
      "Test Data:\n",
      "Shape of anchor images    :  (224, 105, 105, 3)\n",
      "Shape of validation images:  (224, 105, 105, 3)\n",
      "Shape of labels           :  (224,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data:\")\n",
    "print(\"Shape of anchor images    : \", x1_train.shape)\n",
    "print(\"Shape of validation images: \", x2_train.shape)\n",
    "print(\"Shape of labels           : \", y_train.shape)\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "print(\"Test Data:\")\n",
    "print(\"Shape of anchor images    : \", x1_test.shape)\n",
    "print(\"Shape of validation images: \", x2_test.shape)\n",
    "print(\"Shape of labels           : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2e7b2",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f59ff7",
   "metadata": {},
   "source": [
    "## 3) Building and training the siamese network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21855f",
   "metadata": {},
   "source": [
    "### 3.1 Building the base of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86a2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape = [105,105,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "126d6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_base_network():\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Input(shape = inp_shape, name = \"input_image\"),\n",
    "            Conv2D(64, (10, 10), activation = 'relu'),\n",
    "            MaxPooling2D(64, (2,2), padding = 'same'),\n",
    "            \n",
    "            Conv2D(128, (7, 7), activation = 'relu'),\n",
    "            MaxPooling2D(64, (2,2), padding = 'same'),\n",
    "            \n",
    "            Conv2D(128, (4, 4), activation = 'relu'),\n",
    "            MaxPooling2D(64, (2,2), padding = 'same'),\n",
    "            \n",
    "            Conv2D(256, (4, 4), activation = 'relu'),\n",
    "            \n",
    "            Flatten(),\n",
    "            \n",
    "            Dense(4096, activation = 'sigmoid')\n",
    "        ], name = \"BaseNetwork\"\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "894e8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 15:07:41.167420: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n",
      "2023-11-29 15:07:41.211708: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "base_model = make_base_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d53b253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BaseNetwork\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 96, 96, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 48, 48, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 42, 42, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 21, 21, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 18, 18, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fdc6f",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b447b",
   "metadata": {},
   "source": [
    "### 3.2 Building tthe L1Dist layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa24a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(L1Dist, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, validation):\n",
    "        return tf.abs(anchor - validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951de60",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da6cc5",
   "metadata": {},
   "source": [
    "### 3.3 Defining the siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7fb974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    \n",
    "    # Anchor input image to the network\n",
    "    anc_image = Input(shape = inp_shape, name = \"input_image\")\n",
    "    \n",
    "    # Validation input image to the network\n",
    "    validation_image = Input(shape = inp_shape, name = \"Validation_image\")\n",
    "    \n",
    "    # creating a base model\n",
    "    base_model = make_base_network()\n",
    "    \n",
    "    # Encoding the anchor image\n",
    "    anchor = base_model(anc_image)\n",
    "\n",
    "    # Encoding the validation image\n",
    "    validation = base_model(validation_image)\n",
    "    \n",
    "    # Using L1Dist Layer to calculate the L1 distance between the two encodings\n",
    "    distance_layer = L1Dist()\n",
    "    distance_layer._name = \"distance_layer\"\n",
    "    distance = distance_layer(anchor, validation)\n",
    "\n",
    "    \n",
    "    # Defining the output layer\n",
    "    output_layer = Dense(1, activation = 'linear')(distance)\n",
    "    \n",
    "    siamese_model = Model(inputs = [anc_image, validation_image], outputs = output_layer, name = \"SiameseNetwork\")\n",
    "    \n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aece1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Validation_image (InputLayer)  [(None, 105, 105, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " BaseNetwork (Sequential)       (None, 4096)         231635904   ['input_image[0][0]',            \n",
      "                                                                  'Validation_image[0][0]']       \n",
      "                                                                                                  \n",
      " distance_layer (L1Dist)        (None, 4096)         0           ['BaseNetwork[0][0]',            \n",
      "                                                                  'BaseNetwork[1][0]']            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            4097        ['distance_layer[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 231,640,001\n",
      "Trainable params: 231,640,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0835a04b",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e821a54",
   "metadata": {},
   "source": [
    "### 3.4 Compiling and training the siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ef368ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.0001),\n",
    "    loss = BinaryCrossentropy(from_logits = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994f3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.fit([x1_train, x2_train], y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7bf73",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc925a",
   "metadata": {},
   "source": [
    "## 4) Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8413db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    y_hat = y_hat.numpy()\n",
    "    for i in range(len(y_hat)):\n",
    "        if(y_hat[i] >= 0.5):\n",
    "            y_hat[i] = 1\n",
    "        else:\n",
    "            y_hat[i] = 0\n",
    "    \n",
    "    \n",
    "    accuracy = 100*(np.sum(y == y_hat)/m)\n",
    "    print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c9b39",
   "metadata": {},
   "source": [
    "#### Evaluation on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9665f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 809ms/step\n"
     ]
    }
   ],
   "source": [
    "output1 = siamese_model.predict([x1_train, x2_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35463aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 100.0\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.nn.sigmoid(output1)\n",
    "y = y_train\n",
    "model_eval(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37720f",
   "metadata": {},
   "source": [
    "#### Evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dcbae352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 817ms/step\n"
     ]
    }
   ],
   "source": [
    "output2 = siamese_model.predict([x1_test, x2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be20bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.5\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.nn.sigmoid(output2)\n",
    "y = y_test\n",
    "model_eval(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa9368",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d10ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.save(\"../other data/siamese_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4174bd4",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b6d2e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../my data/siamese_model.h5', \n",
    "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f2dc23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
